=====================
第一部分 表格解决方法
=====================

在本书的这一部分中，我们以最简单的形式描述了强化学习算法的几乎所有核心​​思想：状态和动作空间足够小，可以将近似值函数表示为数组或者 *表格*。
在这种情况下，这些方法通常可以找到精确的解决方案，也就是说，它们通常可以找到最佳的价值函数和最优策略。
这与本书下一部分中描述的近似方法形成对比，后者只能找到近似解，但它可以有效地应用于更大的问题。

本书这一部分的第一章描述了强化学习问题特殊情况的解决方法，其中只有一个状态，称为赌博机问题。
第二章描述了我们在本书的其余部分 - 有限马尔可夫决策过程 - 中处理的一般问题公式及其主要思想，包括贝尔曼方程和价值函数。

接下来的三章描述了解决有限马尔可夫决策问题的三种基本方法：动态规划，蒙特卡罗方法和时序差分学习。
每类方法都有其优点和缺点。动态规划方法在数学上得到了很好的发展，但需要一个完整而准确的环境模型。
蒙特卡罗方法不需要模型，并且在概念上很简单，但不适合逐步增量计算。
最后，时差方法不需要模型，完全是增量的，但分析起来更复杂。这些方法在效率和收敛速度方面也有不同的几种方式。

剩下的两章描述了如何将这三类方法结合起来以获得每种方法的最佳特征。
在一章中，我们描述了蒙特卡罗方法的优势如何通过多步自举方法与时间方法的优势相结合。
在本书这一部分的最后一章中，我们将展示如何将时序差分学习方法与模型学习和规划方法（如动态规划）相结合，以获得表格强化学习问题的完整统一解决方案。

.. toctree::
   :maxdepth: 2

   chapter2/multi_armed_bandits
   chapter3/finite_markov_decision_process
   chapter4/dynamic_programming
   chapter5/monte_carlo_methods
   chapter6/temporal_difference_learning
   chapter7/n_step_bootstrapping
   chapter8/planning_and_learning_with_tabular_methods
